# -*- coding: utf-8 -*-
# mitmproxy addon: –ª–æ–≥ –≤—Å–µ—Ö URL –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON-–ø–æ–¥–æ–±–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
import json
import re
from datetime import datetime
from pathlib import Path
from mitmproxy import ctx

CONFIG = {
    # –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—Å–æ–∑–¥–∞—Å—Ç—Å—è —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º)
    "out_dir": "Captured_JSON",
    # –§–∏–ª—å—Ç—Ä –ø–æ —Ö–æ—Å—Ç–∞–º (–æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º, —á—Ç–æ–±—ã –ª–æ–≤–∏—Ç—å –≤–æ–æ–±—â–µ –≤—Å—ë)
    "host_substrings": ["metaquotes", "mt5", "mt4"],
    # –ó–∞–ø–∏—Å—ã–≤–∞—Ç—å –ª–æ–≥ –≤—Å–µ—Ö URL
    "write_urls_log": True,
    # –ü–∏—Å–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Ç–µ–ª –æ—Ç–≤–µ—Ç–æ–≤?
    "save_duplicates": False,
}

BASE_DIR = Path(__file__).parent / CONFIG["out_dir"]
URLS_LOG = BASE_DIR / "urls.log"
counter = 0
seen_hashes = set()

def load(l):
    BASE_DIR.mkdir(parents=True, exist_ok=True)
    if CONFIG["write_urls_log"]:
        URLS_LOG.touch(exist_ok=True)
    ctx.log.info(f"üöÄ JSON sniffer –∑–∞–ø—É—â–µ–Ω. –ü–∞–ø–∫–∞: {BASE_DIR}")

def _match_host(url: str) -> bool:
    if not CONFIG["host_substrings"]:
        return True
    u = url.lower()
    return any(sub in u for sub in CONFIG["host_substrings"])

def _is_jsonish(text: str) -> bool:
    s = text.lstrip()
    if not s:
        return False
    if s[0] in "{[":
        # –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
        try:
            json.loads(text)
            return True
        except Exception:
            # –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–æ–º–∞–Ω–Ω—ã–º ‚Äî —Ç–æ–≥–¥–∞ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            return False
    # –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫ ")]}',\n{...}"
    if s.startswith(")]}',"):
        try:
            json.loads(s.split("\n", 1)[1])
            return True
        except Exception:
            return False
    return False

def _short_hash(b: bytes) -> str:
    try:
        import hashlib
        return hashlib.md5(b).hexdigest()[:10]
    except Exception:
        return f"len{len(b)}"

def response(flow):
    global counter

    req = flow.request
    resp = flow.response

    # –õ–æ–≥ URL, —Å—Ç–∞—Ç—É—Å, content-type
    ct = resp.headers.get("content-type", "")
    line = f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {resp.status_code} {ct} {req.method} {req.url}"
    ctx.log.info(line)
    if CONFIG["write_urls_log"]:
        with URLS_LOG.open("a", encoding="utf-8") as f:
            f.write(line + "\n")

    # –•–æ—Å—Ç –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ —Ñ–∏–ª—å—Ç—Ä? ‚Äì –≤—ã—Ö–æ–¥–∏–º
    if not _match_host(req.pretty_url):
        return

    # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç (mitmproxy —Å–∞–º —Ä–∞–∑–æ–∂–º–µ—Ç gzip/deflate)
    try:
        text = resp.get_text(strict=False)
    except Exception:
        # –ë–∏–Ω–∞—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç/–Ω–µ –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç—Å—è
        return

    if not text:
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ "–ø–æ—Ö–æ–∂–µ –Ω–∞ JSON?"
    if not _is_jsonish(text):
        return

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–ª—É (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    body_bytes = text.encode("utf-8", errors="ignore")
    if not CONFIG["save_duplicates"]:
        h = _short_hash(body_bytes)
        if h in seen_hashes:
            ctx.log.info(f"‚Ü©Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç JSON (hash={h})")
            return
        seen_hashes.add(h)

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞: —Ö–æ—Å—Ç + –ø—É—Ç—å —É–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π
    safe_host = re.sub(r"[^a-zA-Z0-9.-]", "_", req.host or "unknown")
    safe_path = re.sub(r"[^a-zA-Z0-9._-]", "_", (req.path or "/"))[:80]
    counter += 1
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"resp_{counter:04d}_{ts}_{safe_host}{safe_path}.json"
    out_path = BASE_DIR / filename

    try:
        # –∫—Ä–∞—Å–∏–≤–æ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º (—É–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π ")]}'," –ø—Ä–µ—Ñ–∏–∫—Å)
        clean_text = text
        if clean_text.lstrip().startswith(")]}',"):
            clean_text = clean_text.split("\n", 1)[1]

        parsed = json.loads(clean_text)
        with out_path.open("w", encoding="utf-8") as f:
            json.dump(parsed, f, ensure_ascii=False, indent=2)
        ctx.log.info(f"‚úÖ JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path.name} ({len(body_bytes)} –±–∞–π—Ç)")
    except Exception as e:
        # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ —ç—Ç–æ –≤—Å—ë-—Ç–∞–∫–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏–º –∫–∞–∫ —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
        raw_path = out_path.with_suffix(".txt")
        with raw_path.open("w", encoding="utf-8", errors="ignore") as f:
            f.write(text)
        ctx.log.warn(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON ({e}). –°–æ—Ö—Ä–∞–Ω—ë–Ω —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {raw_path.name}")
